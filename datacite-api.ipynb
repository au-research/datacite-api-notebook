{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poking the DataCite API with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used for minting and deleting DataCite DOIs with the DataCite Member API. To execute a code cell, select it and click the play (black triangle) button in the toolbar. You can also use `Ctrl + Enter`.\n",
    "\n",
    "Depending on the platform that you're running this notebook on, execution of code cells - especially those that make a request of the DataCite API - may take some time. Be patient, and in bulk operations you might like to get up and do some stretches or get a coffee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of `datacite-api-config.example.json` named `datacite-api-config.json` and modify it to contain your DataCite Member API username and password. For example:\n",
    "```json\n",
    "{\n",
    "    \"username\" : \"myusername\",\n",
    "    \"password\" : \"mypassword\"\n",
    "}\n",
    "```\n",
    "\n",
    "By default this notebook runs on the test API. Change the line `use_test_api = True` to `use_test_api = False` to use the live API.\n",
    "\n",
    "Then execute the following code cell to perform initial setup. You swill need to execute this code cell once at the beginning of every session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "if not os.path.isfile('doilog.csv'):\n",
    "    with open('doilog.csv', 'w') as csvfile:\n",
    "        logwriter = csv.writer(csvfile)\n",
    "        logwriter.writerow([ 'timestamp', 'username', 'filename', 'doi', 'action' ])\n",
    "\n",
    "with open('datacite-api-config.json') as f:\n",
    "    data = json.load(f)\n",
    "    username = data[\"username\"]\n",
    "    password = data[\"password\"]\n",
    "\n",
    "use_test_api = True\n",
    "\n",
    "if use_test_api:\n",
    "    api_endpoint = 'https://api.test.datacite.org/dois'\n",
    "else:\n",
    "    api_endpoint = 'https://api.datacite.org/dois'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mint bulk Draft DOIs\n",
    "\n",
    "The following code cell will go through all files in the `bulk-mint` directory and attempt to mint a DOI for each one. The DataCite API will reject anything that is not a valid JSON file containing DataCite metadata.\n",
    "\n",
    "Put multiple metadata.json files in the `bulk-mint` directory, and then execute the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'bulk-mint'\n",
    "url = api_endpoint\n",
    "headers = {\n",
    "    'Content-Type': 'application/vnd.api+json',\n",
    "}\n",
    "print('Bulk minting DOIs for files in ' + path)\n",
    "dois = []\n",
    "\n",
    "with os.scandir(path) as it:\n",
    "    for entry in it:\n",
    "        if not entry.name.startswith('.') and entry.is_file():\n",
    "            data = open(path + '/' + entry.name)\n",
    "            print('Attempting to mint DOI for ' + path + '/' + entry.name)\n",
    "            response = requests.request('POST', url, auth=(username, password), data = data, headers = headers)\n",
    "            if (response.headers['Status'] == '201 Created'):\n",
    "                doi = json.loads(response.text)['data']['id']\n",
    "                timestamp = datetime.datetime.now().replace(microsecond=0).astimezone().isoformat()\n",
    "                print(doi + ' minted')\n",
    "                dois.append(doi)\n",
    "                with open('doilog.csv', 'a') as csvfile:\n",
    "                    logwriter = csv.writer(csvfile)\n",
    "                    logwriter.writerow([ timestamp, username, path + '/' + entry.name, doi , 'created' ])\n",
    "            else:\n",
    "                print('DOI not minted')\n",
    "                print(response.headers)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete bulk Draft DOIs\n",
    "\n",
    "The following code cell will attempt to delete all of the DOIs specified in the dois array, which is automatically filled by the bulk minting process.\n",
    "\n",
    "If you want to specify a list of DOIs to delete, put them in the list in the second cell e.g. `dois = ['10.80335/sr34-9h64', '10.80335/5375-5t54', '10.80335/2r04-6k46', '10.80335/drgg-dp97', '10.80335/7yky-cd07']`. Then, execute the second code cell before executing the first code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bulk deleting DOIs in list')\n",
    "for doi in dois:\n",
    "    url = api_endpoint + '/' + urllib.parse.quote_plus(doi)\n",
    "    print('Attempting to delete ' + doi)\n",
    "    response = requests.request('DELETE', url, auth=(username, password), headers=headers)\n",
    "    if (response.headers['Status'] == '204 No Content'):\n",
    "        timestamp = datetime.datetime.now().replace(microsecond=0).astimezone().isoformat()\n",
    "        # timestamp = response.headers['Date']\n",
    "        print(doi + ' deleted')\n",
    "        with open('doilog.csv', 'a') as csvfile:\n",
    "            logwriter = csv.writer(csvfile)\n",
    "            logwriter.writerow([ timestamp, username, '', doi , 'deleted' ])\n",
    "    else:\n",
    "        print(doi + ' not deleted')\n",
    "        print(response.headers)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register, publish, or hide bulk Draft DOIs\n",
    "\n",
    "The following code cell will attempt to register, publish, or hide all of the DOIs specified in the dois array, which is automatically filled by the bulk minting process.\n",
    "\n",
    "Once in Registered or Findable state, a DOI can't be set back to Draft state. This also means that once in Registered or Findable state, a DOI *cannot be deleted*. This is serious, mum.\n",
    "\n",
    "The only option for removing a Findable DOI from the public record is to hide it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 'publish' # Set this to register, publish, or hide\n",
    "\n",
    "payload = '{\\\"data\\\":{\\\"attributes\\\":{\\\"event\\\":\\\"' + action + '\\\"}}}'\n",
    "headers = {\n",
    "    'Content-Type': 'application/vnd.api+json',\n",
    "}\n",
    "print('Bulk ' + action + ' DOIs in list')\n",
    "for doi in dois:\n",
    "    url = api_endpoint + '/' + urllib.parse.quote_plus(doi)\n",
    "    print('Attempting to ' + action + ' ' + doi)\n",
    "    response = requests.request('PUT', url, auth=(username, password), data = payload, headers=headers)\n",
    "    if (response.headers['Status'] == '200 OK'):\n",
    "        timestamp = datetime.datetime.now().replace(microsecond=0).astimezone().isoformat()\n",
    "        # timestamp = response.headers['Date']\n",
    "        print(doi + ' ' + action + ' successful')\n",
    "        with open('doilog.csv', 'a') as csvfile:\n",
    "            logwriter = csv.writer(csvfile)\n",
    "            logwriter.writerow([ timestamp, username, '', doi , action ])\n",
    "    else:\n",
    "        print(doi + ' not deleted')\n",
    "        print(response.headers)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk download DOI metadata\n",
    "\n",
    "The following code cell will attempt to download the metadata for the DOIs specified in the array and save the metadata to JSON files in the `downloaded` directory. Subdirectories for each prefix will be created, and files will be named with the suffix. For example `downloaded/10.80335/1337.json`.\n",
    "\n",
    "One use for this downloaded metadata is for a baseline to use when updating DOIs with new metadata. If you are going to use the JSON for this purpose, it is recommended that you delete metadata fields from the JSON if you are *not* going to update them. The next section contains a code block that will delete metadata fields that you should avoid changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois = ['10.80335/1337']\n",
    "\n",
    "path = 'downloaded'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "url = api_endpoint\n",
    "headers = {\n",
    "    'Content-Type': 'application/vnd.api+json',\n",
    "}\n",
    "print('Bulk downloading metadata for DOIs in array')\n",
    "for doi in dois:\n",
    "    url = api_endpoint + '/' + doi\n",
    "    print('Getting metadata for ' + doi)\n",
    "    response = requests.request(\"GET\", url, auth=(username, password), headers = headers)\n",
    "    data = json.loads(response.text)\n",
    "    prefix = doi.split('/')[0]\n",
    "    suffix = doi.split('/')[1]\n",
    "    print('Writing to ' + path + '/'+ prefix + '/' + suffix + '.json')\n",
    "    if not os.path.exists(path + '/'+ prefix):\n",
    "        os.mkdir(path + '/'+ prefix)\n",
    "    with open(path + '/'+ prefix + '/' + suffix + '.json', 'w+') as jsonfile:\n",
    "        json.dump(data, jsonfile, indent=3)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitise downloaded JSON\n",
    "\n",
    "The following code will go through all the downloaded JSON files and delete the metadata fields you should avoid trying to update.\n",
    "\n",
    "You can add or remove items between the points specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'downloaded'\n",
    "\n",
    "print('Sanitising downloaded JSON')\n",
    "\n",
    "for filename in glob.iglob(path + '/**', recursive=True):\n",
    "    if os.path.isfile(filename) and filename.endswith('.json'): # filter dirs\n",
    "        print('Processing '+ filename)\n",
    "        with open(filename) as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "# Add or remove items after this point. Use a # character before a line to stop that line of code from running.\n",
    "\n",
    "        data['data'].pop('relationships', None)\n",
    "        data['data']['attributes'].pop('xml', None)\n",
    "        data['data']['attributes'].pop('contentUrl', None)\n",
    "        data['data']['attributes'].pop('metadataVersion', None)\n",
    "        data['data']['attributes'].pop('schemaVersion', None)\n",
    "        data['data']['attributes'].pop('source', None)\n",
    "        data['data']['attributes'].pop('isActive', None)\n",
    "        data['data']['attributes'].pop('state', None)\n",
    "        data['data']['attributes'].pop('reason', None)\n",
    "        data['data']['attributes'].pop('landingPage', None)\n",
    "        data['data']['attributes'].pop('viewCount', None)\n",
    "        data['data']['attributes'].pop('viewsOverTime', None)\n",
    "        data['data']['attributes'].pop('downloadCount', None)\n",
    "        data['data']['attributes'].pop('downloadsOverTime', None)\n",
    "        data['data']['attributes'].pop('referenceCount', None)\n",
    "        data['data']['attributes'].pop('citationCount', None)\n",
    "        data['data']['attributes'].pop('citationsOverTime', None)\n",
    "        data['data']['attributes'].pop('partCount', None)\n",
    "        data['data']['attributes'].pop('partOfCount', None)\n",
    "        data['data']['attributes'].pop('versionCount', None)\n",
    "        data['data']['attributes'].pop('versionOfCount', None)\n",
    "        data['data']['attributes'].pop('created', None)\n",
    "        data['data']['attributes'].pop('registered', None)\n",
    "        data['data']['attributes'].pop('published', None)\n",
    "        data['data']['attributes'].pop('updated', None)\n",
    "        \n",
    "# Add or remove items before this point\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(data, file, indent=3)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk update DOIs\n",
    "\n",
    "The following code cell will attempt to update the metadata of all of the DOIs in the `bulk-mint` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'bulk-mint'\n",
    "action = 'update'\n",
    "url = api_endpoint\n",
    "headers = {\n",
    "    'Content-Type': 'application/vnd.api+json',\n",
    "}\n",
    "print('Bulk updating metadata for files in ' + path)\n",
    "dois = []\n",
    "with os.scandir(path) as it:\n",
    "    for entry in it:\n",
    "        if not entry.name.startswith('.') and entry.is_file():\n",
    "            print('Attempting to upload metadata for ' + entry.name)\n",
    "            data = open(path + '/' + entry.name)\n",
    "            metadata = json.load(data)\n",
    "            doi = metadata['data']['id']\n",
    "            print('DOI on record is ' + doi)\n",
    "            url = api_endpoint + '/' + doi\n",
    "            response = requests.request('PUT', url, auth=(username, password), data = json.dumps(metadata), headers = headers)\n",
    "            if (response.headers['Status'] == '200 OK'):\n",
    "                timestamp = datetime.datetime.now().replace(microsecond=0).astimezone().isoformat()\n",
    "                # timestamp = response.headers['Date']\n",
    "                print(doi + ' ' + action + ' successful')\n",
    "                with open('doilog.csv', 'a') as csvfile:\n",
    "                    logwriter = csv.writer(csvfile)\n",
    "                    logwriter.writerow([ timestamp, username, '', doi , action ])\n",
    "            else:\n",
    "                print(doi + ' ' + action + ' unsuccessful')\n",
    "                print(response.headers)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you are trying to work out why your DOI was not minted or deleted, execute the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.headers)\n",
    "print('\\n')\n",
    "print(response.text)\n",
    "json.loads(response.text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
